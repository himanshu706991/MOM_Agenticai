What’s inside

Ingestion for PDF/DOCX/TXT (PyMuPDF, python-docx)

4-agent flow (Extract → Summarize → Critique → Aggregate)

New Step: Final GPT polish (configurable: OpenAI / Ollama / HF)

LangGraph orchestration with 5 nodes

Exports DOCX and PDF to /mnt/data/output/

Configure models (env vars)

LLM_BACKEND = ollama | hf | openai

OLLAMA_MODEL (e.g. llama3)

HF_MODEL (e.g. mistralai/Mistral-7B-Instruct-v0.2)

OPENAI_API_KEY, OPENAI_MODEL

LLM_FINAL_BACKEND = openai | ollama | hf | same

FINAL_MODEL (e.g. gpt-4o-mini)

Open the notebook, set the path to your transcript (or keep the demo), and run the last cell to generate:

/mnt/data/output/Minutes_of_Meeting_FINAL.docx

/mnt/data/output/Minutes_of_Meeting_FINAL.pdf
